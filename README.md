A multi-layered neural network that models the fundamental logic gate XOR by modeling given input and output parameters over a set of boolean values ( logic 0 and logic 1 ).

Project - Lakshya Priyadarshi : official.18lakshya@gmail.com 
B.Tech 2nd Semester, Computer Science & Engineering

    Sigmoid activation function, Batch Gradient Descent algorithm
    Number of layers = 4, Learning rate = 0.1, Epoch = 50000

The mathematical function sigmoid(x) is set as the activation function and randomly-initialized weight / bias matrix are used, which improve along with the process-cycle, by deploying a batch gradient descent with a learning rate of 0.1. The code for the neural network is implemented in Python3.
